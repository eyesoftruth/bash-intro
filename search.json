[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to BASH and Sequence Analysis",
    "section": "",
    "text": "Installing VS Code and FileZilla\nWelcome to the Introduction to BASH class! In this course, we will be exploring the basics of the Bash shell, a powerful tool for interacting with your computer’s operating system. Bash is widely used in bioinformatics for tasks ranging from data processing to system administration. To enhance our learning experience and prepare us for using different bioinformatics software and accessing high-performance computing (HPC) facilities, we will use two key tools: VS Code and FileZilla.\n\nWhy Use VS Code and FileZilla?\nVS Code (Visual Studio Code):\n\nIntegrated Terminal: VS Code comes with an integrated terminal that supports Bash, making it a convenient all-in-one tool for writing and executing shell commands.\nCross-Platform Compatibility: It works on Windows, macOS, and Linux, ensuring all students can use the same tool regardless of their operating system.\nText Editor: VS Code also includes a powerful text editor that supports syntax highlighting and other features that make writing scripts easier and more efficient.\n\nFileZilla:\n\nFile Transfer Protocol: FileZilla is a free, open-source FTP client that allows you to transfer files between your local machine and a remote server. This is particularly useful for managing files and scripts in a remote environment.\nEase of Use: It has an intuitive graphical interface that makes it easy to use, even for beginners.\n\n\n\nInstallation Instructions\nVS Code:\n\n\nWindows:\n\n\nDownload the Visual Studio Code installer for Windows.\nOnce it is downloaded, run the installer (VSCodeUserSetup-{version}.exe). This will only take a minute.\nBy default, VS Code is installed under C:\\Users\\Username\\AppData\\Local\\Programs\\Microsoft VS Code\n\n\nmacOS:\n\n\nDownload Visual Studio Code for macOS.\nOpen the browser’s download list and locate the downloaded app or archive.\nIf archive, extract the archive contents. Use double-click for some browsers or select the ‘magnifying glass’ icon with Safari.\nDrag Visual Studio Code.app to the Applications folder, making it available in the macOS Launchpad.\nOpen VS Code from the Applications folder, by double clicking the icon.\nAdd VS Code to your Dock by right-clicking on the icon, located in the Dock, to bring up the context menu and choosing Options, Keep in Dock.\n\n\nLinux:\n\nVisit the VS Code download page.\nFollow the instructions specific to your distribution (e.g., Ubuntu, Fedora, etc.).\n\n\nFileZilla:\n\n\nWindows:\n\nVisit the FileZilla download page.\nClick on the “Download FileZilla Client” button.\nRun the installer and follow the prompts to complete the installation.\n\nmacOS:\n\nVisit the FileZilla download page.\nClick on the “Download FileZilla Client” button.\nOpen the downloaded file and drag the FileZilla icon to the Applications folder.\n\nLinux:\n\nYou can install FileZilla via your package manager. For example, on Ubuntu, you can use the command:\n\n\n     sudo apt-get install filezilla\n\n\nPreparation for Class\nPlease ensure you have both VS Code and FileZilla installed on your computer before attending the class. This will allow us to dive straight into the practical aspects of learning Bash without any delays.\nWe look forward to helping you develop your skills in Bash scripting and system administration. If you encounter any issues during installation, please do not hesitate to reach out for assistance.",
    "crumbs": [
      "Installing VS Code and FileZilla"
    ]
  },
  {
    "objectID": "First_Time_Accessing_the_Server.html",
    "href": "First_Time_Accessing_the_Server.html",
    "title": "First Time Accessing the Server",
    "section": "",
    "text": "Accessing the Server\nEach student will be provided with a unique user ID (e.g., s-1, s-2, s-3) and the server’s IP address. To access the server, you will use the ssh (Secure Shell) command. SSH allows you to securely connect to the server and interact with it via the command line.",
    "crumbs": [
      "First Time Accessing the Server"
    ]
  },
  {
    "objectID": "First_Time_Accessing_the_Server.html#accessing-the-server",
    "href": "First_Time_Accessing_the_Server.html#accessing-the-server",
    "title": "First Time Accessing the Server",
    "section": "",
    "text": "Using the SSH Command\n\nOpen VS Code Terminal:\n\nLaunch Visual Studio Code.\nOpen the integrated terminal by pressing Ctrl + (backtick) or navigating to Terminal &gt; New Terminal or View &gt; Terminal (depending on VS Code version) from the menu.\n\n\n\n\nConnect to the Server:\n\nIn the terminal, type the following command:\nssh your_user_id@server_ip\nReplace your_user_id with your assigned user ID (e.g., s-1) and server_ip with the provided IP address of the server.\nPress Enter.\n\nEnter Your Password:\n\nYou will be prompted to enter your password. Note that in Linux, when you type your password, nothing will be displayed on the screen (no asterisks or dots) for security reasons. This is different from Windows, where you typically see asterisks.\n\nSuccessful Connection:\n\nIf your credentials are correct, you will be logged into the server and see a welcome message or command prompt.",
    "crumbs": [
      "First Time Accessing the Server"
    ]
  },
  {
    "objectID": "1_Introducing_the_Shell.html",
    "href": "1_Introducing_the_Shell.html",
    "title": "1  Introducing the Shell",
    "section": "",
    "text": "1.1 Accessing the Server\nEach student will be provided with a unique user ID (e.g., s-1, s-2, s-3) and the server’s IP address. To access the server, you will use the ssh (Secure Shell) command. SSH allows you to securely connect to the server and interact with it via the command line.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducing the Shell</span>"
    ]
  },
  {
    "objectID": "1_Introducing_the_Shell.html#accessing-the-server",
    "href": "1_Introducing_the_Shell.html#accessing-the-server",
    "title": "1  Introducing the Shell",
    "section": "",
    "text": "1.1.1 Using the SSH Command\n\nOpen VS Code Terminal:\n\nLaunch Visual Studio Code.\nOpen the integrated terminal by pressing Ctrl + (backtick) or navigating to Terminal &gt; New Terminal or View &gt; Terminal (depending on VS Code version) from the menu.\n\n\n\n\nConnect to the Server:\n\nIn the terminal, type the following command:\nssh your_user_id@server_ip\nReplace your_user_id with your assigned user ID (e.g., s-1) and server_ip with the provided IP address of the server.\nPress Enter.\n\nEnter Your Password:\n\nYou will be prompted to enter your password. Note that in Linux, when you type your password, nothing will be displayed on the screen (no asterisks or dots) for security reasons. This is different from Windows, where you typically see asterisks.\n\nSuccessful Connection:\n\nIf your credentials are correct, you will be logged into the server and see a welcome message or command prompt.\n\n\n\n\n\n1.1.2 What is a Shell?\nA shell is a command-line interface (CLI) that allows users to interact with the operating system by typing commands. It acts as an intermediary between the user and the kernel, interpreting and executing commands entered by the user. The shell is a powerful tool for managing files, running programs, and automating tasks through scripts.\n\n\n1.1.3 Why Use the Shell?\n\nEfficiency: The shell allows users to perform complex tasks with simple commands, which can be more efficient than using a graphical user interface (GUI).\nAutomation: With the shell, users can write scripts to automate repetitive tasks, saving time and reducing errors.\nFlexibility: The shell provides access to a wide range of tools and utilities, making it versatile for different types of tasks.\nControl: Advanced users can have more control over the system and its processes compared to using a GUI.\n\n\n\n1.1.4 The Shell Prompt\nWhen you open a terminal window, you will see a shell prompt. This prompt indicates that the shell is ready to accept commands. The prompt usually looks something like this:\nusername@hostname:~$\nHere’s a breakdown of the components:\n\nusername: Your user name on the system.\nhostname: The name of the computer or server.\n~: The current directory (in this case, ~ represents the home directory).\n$: The prompt symbol for a standard user (it changes to # for the root user).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducing the Shell</span>"
    ]
  },
  {
    "objectID": "1_Introducing_the_Shell.html#understanding-directories",
    "href": "1_Introducing_the_Shell.html#understanding-directories",
    "title": "1  Introducing the Shell",
    "section": "1.2 Understanding Directories",
    "text": "1.2 Understanding Directories\n\n1.2.1 Home Directory\nUpon logging in, you will be in your home directory, usually located at /home/your_user_id. This directory is your personal space on the server. However, the home directory is usually very small and should not be used for extensive work or large data storage.\n\n\n1.2.2 Scratch Directory\nThe /scratch directory (or similar) is a designated area for temporary storage of large files and data processing. This space is typically much larger than your home directory and is intended for heavy computational tasks.\n\n\n1.2.3 Working Directory\nFor our course, you will use /mnt/s-ws/your_user_id as your working directory. This directory provides ample space for your projects and assignments.\n\n\n1.2.4 Navigating Directories\n\nWho Am I? (whoami):\n\nThis command prints your current user ID.\nUsage:\nwhoami\n\nPrint Working Directory (pwd):\n\nThis command displays the full path of your current directory.\nUsage:\npwd\n\nChange Directory (cd):\n\nUse the cd command to navigate to your working directory.\nExample:\ncd /mnt/s-ws/your_user_id\n\n\n\n\n1.2.5 Listing the files in the current directory\n\nls will list of the contents of the current directory\n\nExample:\n\nls\nCommand not found\n\nIf the shell can’t find a program whose name is the command you typed, it will print an error message such as:\n\nks",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducing the Shell</span>"
    ]
  },
  {
    "objectID": "1_Introducing_the_Shell.html#summary",
    "href": "1_Introducing_the_Shell.html#summary",
    "title": "1  Introducing the Shell",
    "section": "1.3 Summary",
    "text": "1.3 Summary\nBy following these steps, you will be able to access the server and navigate the directories effectively. Here’s a quick summary:\n\nUse SSH to connect to the server.\nEnter your password (nothing will be shown as you type).\nUnderstand the purpose of the home directory and /scratch.\nUse /mnt/s-ws/your_user_id as your working directory.\nLearn basic commands (whoami, pwd, ls) and use Tab for auto-completion.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducing the Shell</span>"
    ]
  },
  {
    "objectID": "2_Navigating_Files_and_Directories.html",
    "href": "2_Navigating_Files_and_Directories.html",
    "title": "2  Navigating Files and Directories",
    "section": "",
    "text": "2.1 The File System\nThe part of the operating system responsible for managing files and directories is called the file system. It organizes our data into files, which hold information, and directories (also called “folders”), which hold files or other directories.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Navigating Files and Directories</span>"
    ]
  },
  {
    "objectID": "2_Navigating_Files_and_Directories.html#the-file-system",
    "href": "2_Navigating_Files_and_Directories.html#the-file-system",
    "title": "2  Navigating Files and Directories",
    "section": "",
    "text": "2.1.1 The Root Directory\nThe root directory is the top-level directory in a file system. It is represented by a single forward slash (/). Every other file or directory in the file system is contained within the root directory, either directly or indirectly. Think of it as the starting point of the file system hierarchy.\n\n\n2.1.2 The Home Directory\nThe home directory is a special directory designated for a specific user. It is where users have their personal space to store files and directories. Each user on the system has their own home directory. In most Linux systems, the home directory for a user named “username” would be /home/username. For the root user, the home directory is usually /root.\n\n\n2.1.3 The Uses of /\nThe forward slash (/) serves two important purposes in the file system:\n\nRoot Directory: As mentioned, the single forward slash represents the root directory. It is the base of the file system hierarchy.\nPath Separator: The forward slash is also used to separate directories and files in a path. For example, in the path /home/username/Documents, the slashes separate the directories home, username, and Documents.\n\n\n\n2.1.4 Examples\n\nRoot Directory: The command cd / changes the current directory to the root directory.\nHome Directory: The command cd ~ or cd /home/username changes the current directory to the home directory of the user “username”.\nPath Separator: In the path /home/username/Documents/file.txt, the slashes are used to navigate through the directories from the root to the file file.txt.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Navigating Files and Directories</span>"
    ]
  },
  {
    "objectID": "2_Navigating_Files_and_Directories.html#commands-arguments-and-flags",
    "href": "2_Navigating_Files_and_Directories.html#commands-arguments-and-flags",
    "title": "2  Navigating Files and Directories",
    "section": "2.2 Commands, Arguments, and Flags",
    "text": "2.2 Commands, Arguments, and Flags\nWhen working with the command line, you will often use commands. Commands are instructions you give to the computer to perform a specific task. A command can be followed by arguments (or parameters) and flags (or options) to modify its behavior.\n\n\nCommand: The base instruction to perform a task. For example, ls is a command that lists directory contents.\nArguments: Additional information you provide to the command. For example, in ls /home/username, /home/username is an argument specifying the directory to list.\nFlags: Options that modify the behavior of the command. Flags are usually preceded by a hyphen. For example, ls -F uses the -F flag to modify the output.\n\n\n2.2.1 Example with ls and the -F Flag\nThe ls command lists the contents of a directory. By default, it shows the names of the files and directories. Adding the -F flag to ls appends a character to each file name to indicate the type of file. For instance, a forward slash (/) is added to directories, an asterisk (*) to executable files, and an at sign (@) to symbolic links.\nExample:\n# ls -F /home/username\nls -F /mnt/s-ws/everyone/\nThis command lists the contents of /home/username and appends type-indicating characters to each name.\n\n\n2.2.2 Other Useful Flags for ls\n\n-l: Lists in long format, providing detailed information like permissions, number of links, owner, group, size, and timestamp.\n\n# -l gives you more details on all files\nls -l /mnt/s-ws/everyone/\n\n-a: Lists all files, including hidden files (those starting with a dot).\n\n# -l gives you more details on all files\nls -a /mnt/s-ws/everyone/\n\n-h: With -l, shows sizes in human-readable format (e.g., KB, MB).\n\n\nls -l -h /mnt/s-ws/everyone/\n\n# you can also merge flags\nls -lh /mnt/s-ws/everyone/\n\n-R: Lists all subdirectories recursively.\n-t: Sorts by modification time, with the newest files first.\n-r: Reverses the order of the sort.\n-d: Lists directories themselves, not their contents.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Navigating Files and Directories</span>"
    ]
  },
  {
    "objectID": "2_Navigating_Files_and_Directories.html#clearing-your-terminal",
    "href": "2_Navigating_Files_and_Directories.html#clearing-your-terminal",
    "title": "2  Navigating Files and Directories",
    "section": "2.3 Clearing Your Terminal",
    "text": "2.3 Clearing Your Terminal\nWhen working in the terminal, your screen can quickly become cluttered with output from various commands. To clear the terminal and create a fresh workspace, you can use the clear command.\n\n2.3.1 Using the clear Command\nThe clear command clears all the previous output in the terminal, giving you a clean slate. Simply type clear and press Enter:\nclear\nThis will remove all previous text from the screen, making it easier to focus on new commands and their output.\n\n\n2.3.2 Navigating Command History\nThe terminal keeps a history of the commands you have entered. You can quickly navigate through your previous commands using the up and down arrow keys:\n\n↑ Up Arrow: Press the ↑ (up arrow) key to scroll through the commands you have previously entered, starting with the most recent.\n↓ Down Arrow: Press the ↓ (down arrow) key to scroll forward through the commands if you have gone back in your command history.\n\nUsing these keys can save you time, especially when you need to re-run or modify previous commands.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Navigating Files and Directories</span>"
    ]
  },
  {
    "objectID": "2_Navigating_Files_and_Directories.html#using-tab-for-auto-complete",
    "href": "2_Navigating_Files_and_Directories.html#using-tab-for-auto-complete",
    "title": "2  Navigating Files and Directories",
    "section": "2.4 Using Tab for Auto-Complete",
    "text": "2.4 Using Tab for Auto-Complete\nThe tab key can significantly enhance your efficiency in the terminal by providing auto-completion for commands, file names, and directories. Here’s how you can use it:\n\nAuto-Complete Commands: Start typing a command and press the tab key. If the command is unique, the terminal will auto-complete it. For example, typing cle and pressing tab will auto-complete to clear if no other commands start with cle.\nAuto-Complete File and Directory Names: When typing file or directory names, you can use the tab key to quickly complete the names. For instance, if you have a file named document.txt in the current directory, typing doc and pressing tab will auto-complete the name to document.txt.\nList Possible Completions: If there are multiple possible completions, pressing the tab key twice will list all the possible completions. For example, if you have files named document1.txt, document2.txt, and document3.txt, typing doc and pressing tab twice will list all three options.\n\nUsing the tab key for auto-completion can save you time and help avoid errors when typing long commands or file names.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Navigating Files and Directories</span>"
    ]
  },
  {
    "objectID": "2_Navigating_Files_and_Directories.html#getting-help",
    "href": "2_Navigating_Files_and_Directories.html#getting-help",
    "title": "2  Navigating Files and Directories",
    "section": "2.5 Getting Help",
    "text": "2.5 Getting Help\nWhen working in the terminal, you often need more information about commands and their options. Two essential tools for this are the --help option and the man (manual) command.\n\n2.5.1 Using --help\nMost commands in the terminal have a --help option that provides a brief overview of how to use the command, along with a list of available options and flags. For example, to get help on the ls command, you can type:\nls --help\nThis command will display a brief description of ls and its options. The output typically includes: - A summary of what the command does. - A list of available flags and options. - Short descriptions of each flag and option.\n\n\n2.5.2 Using man\nThe man command displays the manual page for a command, providing more detailed information than --help. To read the manual page for the ls command, you can type:\nman ls\nThe manual page will include: - NAME: The name of the command and a brief description. - SYNOPSIS: The syntax for using the command. - DESCRIPTION: A detailed description of what the command does. - OPTIONS: A comprehensive list of all options and flags, with explanations. - EXAMPLES: Examples of how to use the command.\n\n\n2.5.3 Reading the Output\nWhen you use --help or man, the output will appear in the terminal. Here’s how to navigate and quit these outputs:\n\n--help Output: The --help output typically fits within a single screen. You can scroll through it using the scroll bar or your mouse.\nman Output: The man output is displayed in a pager (usually less), which allows you to scroll through the document.\n\n\n2.5.3.1 Navigating man Output\n\nScroll Down: Use the down arrow key or the Page Down key to scroll down.\nScroll Up: Use the up arrow key or the Page Up key to scroll up.\nSearch: Press / followed by a keyword to search within the manual page.\nQuit: Press q to quit and return to the terminal prompt.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Navigating Files and Directories</span>"
    ]
  },
  {
    "objectID": "2_Navigating_Files_and_Directories.html#special-folders-.-and-..",
    "href": "2_Navigating_Files_and_Directories.html#special-folders-.-and-..",
    "title": "2  Navigating Files and Directories",
    "section": "2.6 Special Folders: . and ..",
    "text": "2.6 Special Folders: . and ..\nIn the file system, there are two special directory references: . (dot) and .. (dot dot). These are used to represent the current directory and the parent directory, respectively. Understanding these references is crucial for navigating the file system efficiently.\n\n2.6.1 The . (Dot) Directory\nThe . directory refers to the current directory. It is useful when you need to execute commands or scripts in the current directory or specify the current directory explicitly.\n\n2.6.1.1 Example:\n# List the contents of the current directory\nls .\n\n\n\n2.6.2 The .. (Dot Dot) Directory\nThe .. directory refers to the parent directory, which is one level up in the file system hierarchy. This is helpful for moving up directories without specifying the full path.\n\n2.6.2.1 Example:\n# Move up one directory\ncd ..\n\n\n\n2.6.3 Nested .. Directories\nYou can chain multiple .. references to move up several levels in the directory hierarchy. Each .. moves you up one directory level.\n\n2.6.3.1 Example:\n# Move up two directories and then into a folder named folder_name\n# cd ../../folder_name\ncd ../../data\nIn this example: - The first .. moves up one level. - The second .. moves up another level. - After moving up two levels, the command then moves into the directory data.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Navigating Files and Directories</span>"
    ]
  },
  {
    "objectID": "2_Navigating_Files_and_Directories.html#absolute-path-and-relative-path",
    "href": "2_Navigating_Files_and_Directories.html#absolute-path-and-relative-path",
    "title": "2  Navigating Files and Directories",
    "section": "2.7 Absolute Path and Relative Path",
    "text": "2.7 Absolute Path and Relative Path\n\n2.7.1 Absolute Path\nAn absolute path is a complete path from the root directory (/) to the desired file or directory. It always starts with a forward slash and provides the full location, ensuring that you can access the file or directory from anywhere in the file system.\n\n2.7.1.1 Example:\nIf you have a directory named FastQC inside /mnt/s-ws/everyone, the absolute path to this directory would be:\n/mnt/s-ws/everyone/FastQC\n\n\n\n2.7.2 Relative Path\nA relative path specifies a location relative to the current directory. It does not start with a forward slash and can use special directory references like . (current directory) and .. (parent directory) to navigate through the file system.\n\n2.7.2.1 Example:\nAssuming your current directory is /mnt/s-ws/everyone:\n\nTo access the FastQC directory, you can use the relative path:\ncd FastQC\nTo go up one level and then into another directory (e.g., Quiz), you can use:\ncd ../Quiz\n\n\n\n\n2.7.3 Example Paths\nGiven the absolute path /mnt/s-ws/everyone and a folder FastQC inside it:\n\nAccessing FastQC using an absolute path:\ncd /mnt/s-ws/everyone/FastQC\nThis command changes the directory to FastQC from anywhere in the file system.\nAccessing FastQC using a relative path:\ncd FastQC\nThis command changes the directory to FastQC assuming you are already in /mnt/s-ws/everyone.\n\n\n\n2.7.4 Summary\n\nThe file system manages files and directories.\nThe root directory (/) is the top-level directory.\nThe home directory is a personal directory for each user.\nThe forward slash (/) is used both as the root directory and as a separator in file paths.\nCommands are instructions, arguments provide additional information, and flags modify behavior.\nThe ls command lists directory contents, and flags like -F, -l, -a, -h, and -R enhance its functionality.\npwd prints the user’s current working directory.\nls [path] prints a listing of a specific file or directory; ls on its own lists the current working directory.\ncd [path] changes the current working directory.\nMost commands take options that begin with a single -.\n/ on its own is the root directory of the whole file system.\n. on its own means ‘the current directory’; .. means ‘the directory above the current one’.\nAbsolute Path: Provides the full path from the root directory, ensuring access from anywhere in the file system. Example: /mnt/s-ws/everyone/FastQC.\nRelative Path: Specifies the location relative to the current directory. Example: FastQC from /mnt/s-ws/everyone.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Navigating Files and Directories</span>"
    ]
  },
  {
    "objectID": "3_Working_With_Files_and_Directories.html",
    "href": "3_Working_With_Files_and_Directories.html",
    "title": "3  Working With Files and Directories",
    "section": "",
    "text": "3.1 Creating directories\nWe now know how to explore files and directories, but how do we create them in the first place?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working With Files and Directories</span>"
    ]
  },
  {
    "objectID": "3_Working_With_Files_and_Directories.html#creating-directories",
    "href": "3_Working_With_Files_and_Directories.html#creating-directories",
    "title": "3  Working With Files and Directories",
    "section": "",
    "text": "3.1.1 Step one: see where we are and what we already have\npwd\n# move to the directory in /mnt/s-ws/ designated for you\n# cd /mnt/s-ws/{your id}\ncd /mnt/s-ws/mamun\n# view the current contents\nls -F\n\n\n3.1.2 Create a directory\nLet’s create a new directory called thesis using the command mkdir thesis (which has no output):\n\nmkdir thesis\nAs you might guess from its name, mkdir means ‘make directory’. Since thesis is a relative path (i.e., does not have a leading slash, like /what/ever/thesis), the new directory is created in the current working directory:\n\nls -F\nSince we’ve just created the thesis directory, there’s nothing in it yet:\n\nls -F thesis\nNote that mkdir is not limited to creating single directories one at a time. The -p option allows mkdir to create a directory with nested subdirectories in a single operation:\nmkdir -p ../project/data ../project/results\nThe -R option to the ls command will list all nested subdirectories within a directory. Let’s use ls -FR to recursively list the new directory hierarchy we just created in the project directory:\nls -FR ../project",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working With Files and Directories</span>"
    ]
  },
  {
    "objectID": "3_Working_With_Files_and_Directories.html#good-names-for-files-and-directories",
    "href": "3_Working_With_Files_and_Directories.html#good-names-for-files-and-directories",
    "title": "3  Working With Files and Directories",
    "section": "3.2 Good names for files and directories",
    "text": "3.2 Good names for files and directories\nComplicated names of files and directories can make your life painful when working on the command line. Here we provide a few useful tips for the names of your files and directories.\nDon’t use spaces.\nSpaces can make a name more meaningful, but since spaces are used to separate arguments on the command line it is better to avoid them in names of files and directories. You can use - or _ instead (e.g. north-pacific-gyre/ rather than north pacific gyre/). To test this out, try typing mkdir north pacific gyre and see what directory (or directories!) are made when you check with ls -F.\nDon’t begin the name with - (dash).\nCommands treat names starting with - as options.\nStick with letters, numbers, . (period or ‘full stop’), - (dash) and _ (underscore).\nMany other characters have special meanings on the command line. We will learn about some of these during this lesson. There are special characters that can cause your command to not work as expected and can even result in data loss.\nIf you need to refer to names of files or directories that have spaces or other special characters, you should surround the name in single quotes (’’).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working With Files and Directories</span>"
    ]
  },
  {
    "objectID": "3_Working_With_Files_and_Directories.html#create-a-text-file",
    "href": "3_Working_With_Files_and_Directories.html#create-a-text-file",
    "title": "3  Working With Files and Directories",
    "section": "3.3 Create a text file",
    "text": "3.3 Create a text file\nLet’s change our working directory to thesis using cd, then run a text editor called Nano to create a file called draft.txt:\ncd thesis\nnano draft.txt\nLet’s type in a few lines of text.\n\nOnce we’re happy with our text, we can press Ctrl+O (press the Ctrl or Control key and, while holding it down, press the O key) to write our data to disk. We will be asked to provide a name for the file that will contain our text. Press Return to accept the suggested default of draft.txt.\nOnce our file is saved, we can use Ctrl+X to quit the editor and return to the shell.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working With Files and Directories</span>"
    ]
  },
  {
    "objectID": "3_Working_With_Files_and_Directories.html#viewing-files-in-the-terminal",
    "href": "3_Working_With_Files_and_Directories.html#viewing-files-in-the-terminal",
    "title": "3  Working With Files and Directories",
    "section": "3.4 Viewing Files in the Terminal",
    "text": "3.4 Viewing Files in the Terminal\nWhen working with files in the terminal, several commands can help you view their contents efficiently. Here, we will discuss cat, head, tail, less, and more, highlighting their uses and differences.\n\n3.4.1 cat\nThe cat command (short for “concatenate”) is used to display the contents of a file. It is best suited for small files because it outputs the entire content to the terminal.\n\n3.4.1.1 Example:\ncat filename.txt\nThis command will display the entire content of filename.txt.\n\n\n\n3.4.2 head\nThe head command displays the first few lines of a file. By default, it shows the first 10 lines, but you can specify a different number of lines with the -n option.\n\n3.4.2.1 Example:\nhead filename.txt\nhead -n 20 filename.txt\nThe first command shows the first 10 lines of filename.txt, while the second command shows the first 20 lines.\n\n\n\n3.4.3 tail\nThe tail command displays the last few lines of a file. By default, it shows the last 10 lines, but you can specify a different number of lines with the -n option.\n\n3.4.3.1 Example:\ntail filename.txt\ntail -n 20 filename.txt\nThe first command shows the last 10 lines of filename.txt, while the second command shows the last 20 lines.\n\n\n\n3.4.4 less\nThe less command is a pager that allows you to view the contents of a file one screen at a time. It is particularly useful for large files, as it does not load the entire file into memory at once.\n\n3.4.4.1 Example:\nless filename.txt\nUse the arrow keys to scroll through the file. Press q to quit and return to the terminal.\n\n\n\n3.4.5 more\nThe more command is another pager similar to less. It allows you to view the contents of a file one screen at a time. However, more is less powerful and flexible than less.\n\n3.4.5.1 Example:\nmore filename.txt\nUse the spacebar to scroll down one screen at a time. Press q to quit.\n\n\n\n3.4.6 Difference Between cat and less/more\n\ncat: Displays the entire content of a file at once. It is useful for small files but can be overwhelming for large files since all content is outputted at once.\nless/more: Both are pagers that display one screen of content at a time, making them more suitable for large files. less is generally preferred over more because it provides more features, such as backward navigation and better performance.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working With Files and Directories</span>"
    ]
  },
  {
    "objectID": "3_Working_With_Files_and_Directories.html#moving-files-and-directories",
    "href": "3_Working_With_Files_and_Directories.html#moving-files-and-directories",
    "title": "3  Working With Files and Directories",
    "section": "3.5 Moving files and directories",
    "text": "3.5 Moving files and directories\nIn our thesis directory we have a file draft.txt which isn’t a particularly informative name, so let’s change the file’s name using mv, which is short for ‘move’:\nmv thesis/draft.txt thesis/quotes.txt\nThe first argument tells mv what we’re ‘moving’, while the second is where it’s to go. In this case, we’re moving thesis/draft.txt to thesis/quotes.txt, which has the same effect as renaming the file. Sure enough, ls shows us that thesis now contains one file called quotes.txt:\nls thesis\nOne must be careful when specifying the target file name, since mv will silently overwrite any existing file with the same name, which could lead to data loss. By default, mv will not ask for confirmation before overwriting files. However, an additional option, mv -i (or mv --interactive), will cause mv to request such confirmation.\nNote that mv also works on directories.\nLet’s move quotes.txt into the current working directory. We use mv once again, but this time we’ll use just the name of a directory as the second argument to tell mv that we want to keep the filename but put the file somewhere new. (This is why the command is called ‘move’.) In this case, the directory name we use is the special directory name . that we mentioned earlier.\nmv thesis/quotes.txt .",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working With Files and Directories</span>"
    ]
  },
  {
    "objectID": "3_Working_With_Files_and_Directories.html#copying-files-and-directories",
    "href": "3_Working_With_Files_and_Directories.html#copying-files-and-directories",
    "title": "3  Working With Files and Directories",
    "section": "3.6 Copying files and directories",
    "text": "3.6 Copying files and directories\nThe cp command works very much like mv, except it copies a file instead of moving it. We can check that it did the right thing using ls with two paths as arguments — like most Unix commands, ls can be given multiple paths at once:\ncp quotes.txt thesis/quotations.txt\nls quotes.txt thesis/quotations.txt\nWe can also copy a directory and all its contents by using the recursive option -r, e.g. to back up a directory:\ncp -r thesis thesis_backup\nWe can check the result by listing the contents of both the thesis and thesis_backup directory:\n$ ls thesis thesis_backup\nIt is important to include the -r flag. If you want to copy a directory and you omit this option you will see a message that the directory has been omitted because -r not specified.\n$ cp thesis thesis_backup\ncp: -r not specified; omitting directory 'thesis'",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working With Files and Directories</span>"
    ]
  },
  {
    "objectID": "3_Working_With_Files_and_Directories.html#removing-files-and-directories",
    "href": "3_Working_With_Files_and_Directories.html#removing-files-and-directories",
    "title": "3  Working With Files and Directories",
    "section": "3.7 Removing files and directories",
    "text": "3.7 Removing files and directories\nReturning to the shell-lesson-data/exercise-data/writing directory, let’s tidy up this directory by removing the quotes.txt file we created. The Unix command we’ll use for this is rm (short for ‘remove’):\nrm quotes.txt\nWe can confirm the file has gone using ls:\nls quotes.txt\n\n\n\n\n\n\nDeleting Is Forever\n\n\n\nThe Unix shell doesn’t have a trash bin that we can recover deleted files from (though most graphical interfaces to Unix do). Instead, when we delete files, they are unlinked from the file system so that their storage space on disk can be recycled. Tools for finding and recovering deleted files do exist, but there’s no guarantee they’ll work in any particular situation, since the computer may recycle the file’s disk space right away.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working With Files and Directories</span>"
    ]
  },
  {
    "objectID": "3_Working_With_Files_and_Directories.html#using-rm-safely",
    "href": "3_Working_With_Files_and_Directories.html#using-rm-safely",
    "title": "3  Working With Files and Directories",
    "section": "3.8 Using rm Safely",
    "text": "3.8 Using rm Safely\nWhat happens when we execute rm -i thesis_backup/quotations.txt? Why would we want this protection when using rm?\n\nSolution (Solution). \nrm: remove regular file 'thesis_backup/quotations.txt'? y\nThe -i option will prompt before (every) removal (use Y to confirm deletion or N to keep the file). The Unix shell doesn’t have a trash bin, so all the files removed will disappear forever. By using the -i option, we have the chance to check that we are deleting only the files that we want to remove.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working With Files and Directories</span>"
    ]
  },
  {
    "objectID": "3_Working_With_Files_and_Directories.html#using-wildcards-for-accessing-multiple-files-at-once",
    "href": "3_Working_With_Files_and_Directories.html#using-wildcards-for-accessing-multiple-files-at-once",
    "title": "3  Working With Files and Directories",
    "section": "3.9 Using Wildcards for Accessing Multiple Files at Once",
    "text": "3.9 Using Wildcards for Accessing Multiple Files at Once\nWildcards are special characters that allow you to access multiple files at once. They are particularly useful for handling groups of files without needing to list each one individually.\n\n3.9.1 The Asterisk (*)\nThe * wildcard represents zero or more characters. For example, in the shell-lesson-data/exercise-data/alkanes directory:\n\n*.pdb matches all files ending with .pdb, such as ethane.pdb, propane.pdb, and any other files with the .pdb extension.\np*.pdb matches files starting with the letter p and ending with .pdb, such as pentane.pdb and propane.pdb.\n\ncd ../mamun/shell-lesson-data/exercise-data/alkanes/\nls *.pdb\nThis command lists all .pdb files in the current directory. If you use:\nls p*.pdb\nIt lists only .pdb files that start with p.\n\n\n3.9.2 The Question Mark (?)\nThe ? wildcard represents exactly one character. For example:\n\n?ethane.pdb could match methane.pdb but not ethane.pdb, because ? represents exactly one character.\n*ethane.pdb matches both ethane.pdb and methane.pdb, as the * can represent zero or more characters.\n\n\n\n3.9.3 Combining Wildcards\nWildcards can be combined for more specific patterns. For example:\n\n???ane.pdb matches files with exactly three characters followed by ane.pdb, such as cubane.pdb, ethane.pdb, and octane.pdb.\n\n\n\n3.9.4 Handling Non-Matching Wildcards\nIf a wildcard pattern does not match any files, the shell passes the pattern as it is to the command, which can result in an error. For example, if you type:\nls *.pdf\nin a directory containing only .pdb files, you will receive an error stating that no such file or directory exists.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working With Files and Directories</span>"
    ]
  },
  {
    "objectID": "3_Working_With_Files_and_Directories.html#summary",
    "href": "3_Working_With_Files_and_Directories.html#summary",
    "title": "3  Working With Files and Directories",
    "section": "3.10 Summary",
    "text": "3.10 Summary\n\ncp [old] [new] copies a file.\nmkdir [path] creates a new directory.\nmv [old] [new] moves (renames) a file or directory.\nrm [path] removes (deletes) a file.\ncat: Use for small files to quickly view the entire content.\nhead: Use to view the beginning of a file.\ntail: Use to view the end of a file.\nless: Use for large files to navigate through content efficiently.\nmore: Similar to less, but with fewer features.\n* matches zero or more characters in a filename, so *.txt matches all files ending in .txt.\n? matches any single character in a filename, so ?.txt matches a.txt but not any.txt.\nUse of the Control key may be described in many ways, including Ctrl-X, Control-X, and ^X.\nThe shell does not have a trash bin: once something is deleted, it’s really gone.\nMost files’ names are something.extension. The extension isn’t required, and doesn’t guarantee anything, but is normally used to indicate the type of data in the file.\nDepending on the type of work you do, you may need a more powerful text editor than Nano.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working With Files and Directories</span>"
    ]
  },
  {
    "objectID": "4_Pipes_and_Filters.html",
    "href": "4_Pipes_and_Filters.html",
    "title": "4  Pipes and Filters",
    "section": "",
    "text": "4.1 wc ‘word count’ command\nwc is the ‘word count’ command: it counts the number of lines, words, and characters in files (returning the values in that order from left to right).\nLet’s run an example command:\nIf we run the command wc *.pdb, the * in *.pdb matches zero or more characters, so the shell turns *.pdb into a list of all .pdb files in the current directory:\nNote that wc *.pdb also shows the total number of all lines in the last line of the output.\nIf we run wc -l instead of just wc, the output shows only the number of lines per file:\nThe -m and -w options can also be used with the wc command to show only the number of characters or the number of words, respectively.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Pipes and Filters</span>"
    ]
  },
  {
    "objectID": "4_Pipes_and_Filters.html#wc-word-count-command",
    "href": "4_Pipes_and_Filters.html#wc-word-count-command",
    "title": "4  Pipes and Filters",
    "section": "",
    "text": "wc cubane.pdb\n\nwc *.pdb\n\n\nwc -l *.pdb\n\n\n\n\n\n\n\nWhy Isn’t It Doing Anything?\n\n\n\nWhat happens if a command is supposed to process a file, but we don’t give it a filename? For example, what if we type:\n$ wc -l\nbut don’t type *.pdb (or anything else) after the command? Since it doesn’t have any filenames, wc assumes it is supposed to process input given at the command prompt, so it just sits there and waits for us to give it some data interactively. From the outside, though, all we see is it sitting there, and the command doesn’t appear to do anything.\nIf you make this kind of mistake, you can escape out of this state by holding down the control key (Ctrl) and pressing the letter C once: Ctrl+C. Then release both keys.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Pipes and Filters</span>"
    ]
  },
  {
    "objectID": "4_Pipes_and_Filters.html#capturing-output-from-commands-the-redirect-command",
    "href": "4_Pipes_and_Filters.html#capturing-output-from-commands-the-redirect-command",
    "title": "4  Pipes and Filters",
    "section": "4.2 Capturing output from commands: the > (redirect) command",
    "text": "4.2 Capturing output from commands: the &gt; (redirect) command\nWhich of these files contains the fewest lines? It’s an easy question to answer when there are only six files, but what if there were 6000? Our first step toward a solution is to run the command:\n$ wc -l *.pdb &gt; lengths.txt\nThe greater than symbol, &gt;, tells the shell to redirect the command’s output to a file instead of printing it to the screen. This command prints no screen output, because everything that wc would have printed has gone into the file lengths.txt instead. If the file doesn’t exist prior to issuing the command, the shell will create the file. If the file exists already, it will be silently overwritten, which may lead to data loss. Thus, redirect commands require caution.\nls lengths.txt confirms that the file exists:\n$ ls lengths.txt\nWe can now send the content of lengths.txt to the screen using cat lengths.txt. The cat command gets its name from ‘concatenate’ i.e. join together, and it prints the contents of files one after another. There’s only one file in this case, so cat just shows us what it contains:\n$ cat lengths.txt",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Pipes and Filters</span>"
    ]
  },
  {
    "objectID": "4_Pipes_and_Filters.html#filtering-output",
    "href": "4_Pipes_and_Filters.html#filtering-output",
    "title": "4  Pipes and Filters",
    "section": "4.3 Filtering output",
    "text": "4.3 Filtering output\nNext we’ll use the sort command to sort the contents of the lengths.txt file. But first we’ll do an exercise to learn a little about the sort command:\n\n4.3.1 What Does sort -n Do?\nThe file shell-lesson-data/exercise-data/numbers.txt contains some lines with numbers:\nsort ../numbers.txt\n\nsort -n ../numbers.txt\nThe -n option specifies a numerical rather than an alphanumerical sort.\nWe will also use the -n option to specify that the sort is numerical instead of alphanumerical. This does not change the file; instead, it sends the sorted result to the screen:\nsort -n lengths.txt\nWe can put the sorted list of lines in another temporary file called sorted-lengths.txt by putting &gt; sorted-lengths.txt after the command, just as we used &gt; lengths.txt to put the output of wc into lengths.txt. Once we’ve done that, we can run another command called head to get the first few lines in sorted-lengths.txt:\nsort -n lengths.txt &gt; sorted-lengths.txt\nhead -n 1 sorted-lengths.txt\nUsing -n 1 with head tells it that we only want the first line of the file; -n 20 would get the first 20, and so on. Since sorted-lengths.txt contains the lengths of our files ordered from least to greatest, the output of head must be the file with the fewest lines",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Pipes and Filters</span>"
    ]
  },
  {
    "objectID": "4_Pipes_and_Filters.html#the-operator",
    "href": "4_Pipes_and_Filters.html#the-operator",
    "title": "4  Pipes and Filters",
    "section": "4.4 The >> operator",
    "text": "4.4 The &gt;&gt; operator\n\n4.4.1 Using &gt;&gt; in Bash Commands\nIn Bash, the &gt;&gt; operator is used to append the output of a command to a file. If the file does not already exist, it will be created. This operator is particularly useful when you want to add content to the end of an existing file without overwriting its current content.\n\n\n4.4.2 Syntax\ncommand &gt;&gt; filename\n\ncommand: The command whose output you want to append.\nfilename: The file to which the output will be appended.\n\n\n\n4.4.3 Example\nConsider you have a file named logfile.txt and you want to append the current date and time to it each time a certain script runs.\n\n4.4.3.1 Step 1: Create or check the initial content of logfile.txt\necho \"Initial log entry\" &gt; logfile.txt\ncat logfile.txt\n\n\n4.4.3.2 Step 2: Append the date and time to logfile.txt\ndate &gt;&gt; logfile.txt\n\n\n4.4.3.3 Step 3: Check the updated content of logfile.txt\ncat logfile.txt\n\n\n\n4.4.4 Multiple Appends\nYou can use the &gt;&gt; operator multiple times to append different outputs to the same file. For example:\necho \"First append\" &gt;&gt; logfile.txt\necho \"Second append\" &gt;&gt; logfile.txt",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Pipes and Filters</span>"
    ]
  },
  {
    "objectID": "4_Pipes_and_Filters.html#passing-output-to-another-command",
    "href": "4_Pipes_and_Filters.html#passing-output-to-another-command",
    "title": "4  Pipes and Filters",
    "section": "4.5 Passing output to another command",
    "text": "4.5 Passing output to another command\nIn our example of finding the file with the fewest lines, we are using two intermediate files lengths.txt and sorted-lengths.txt to store output. This is a confusing way to work because even once you understand what wc, sort, and head do, those intermediate files make it hard to follow what’s going on. We can make it easier to understand by running sort and head together:\n$ sort -n lengths.txt | head -n 1\n  9  methane.pdb\nThe vertical bar, |, between the two commands is called a pipe. It tells the shell that we want to use the output of the command on the left as the input to the command on the right.\nThis has removed the need for the sorted-lengths.txt file.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Pipes and Filters</span>"
    ]
  },
  {
    "objectID": "4_Pipes_and_Filters.html#combining-multiple-commands",
    "href": "4_Pipes_and_Filters.html#combining-multiple-commands",
    "title": "4  Pipes and Filters",
    "section": "4.6 Combining multiple commands",
    "text": "4.6 Combining multiple commands\nNothing prevents us from chaining pipes consecutively. We can for example send the output of wc directly to sort, and then send the resulting output to head. This removes the need for any intermediate files.\nWe’ll start by using a pipe to send the output of wc to sort:\n$ wc -l *.pdb | sort -n\n   9 methane.pdb\n  12 ethane.pdb\n  15 propane.pdb\n  20 cubane.pdb\n  21 pentane.pdb\n  30 octane.pdb\n 107 total\nWe can then send that output through another pipe, to head, so that the full pipeline becomes:\n$ wc -l *.pdb | sort -n | head -n 1\n   9  methane.pdb\nThis is exactly like a mathematician nesting functions like log(3x) and saying ‘the log of three times x’. In our case, the algorithm is ‘head of sort of line count of *.pdb’.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Pipes and Filters</span>"
    ]
  },
  {
    "objectID": "4_Pipes_and_Filters.html#grep-a-powerful-tool-for-pattern-search",
    "href": "4_Pipes_and_Filters.html#grep-a-powerful-tool-for-pattern-search",
    "title": "4  Pipes and Filters",
    "section": "4.7 grep a powerful tool for pattern search",
    "text": "4.7 grep a powerful tool for pattern search\nThe grep command is a powerful tool used in Unix-like operating systems to search for patterns in text. It can be used to find specific lines in files that match a given pattern. The basic syntax of the grep command is as follows: grep [options] pattern [file...] - [options]: Optional flags that modify the behavior of the grep command. - pattern: The text pattern you want to search for. - [file...]: Optional file names or paths where you want to search for the pattern. If no files are specified, grep will read from standard input (e.g., data piped into it).\nLet’s create a file using nano named example.txt with the following content:\nThis is a sample file. It contains some lines. Let’s search for a word in this file. The word we’ll search for is “search.”\n\ngrep \"search\" example.txt\nThe output would be:\nLet's search for a word in this file.\nThe word we'll search for is \"search.\"\n\n\n4.7.1 Common Options\n\n-i: Ignore case distinctions in the pattern and input files.\n-v: Invert the match, displaying lines that do not match the pattern.\n-r or -R: Recursively search directories for the pattern.\n-l: Print only the names of files with matching lines.\n-n: Prefix each line of output with the line number within its file.\n-c: Print only a count of matching lines per file.\n-H: Print the filename for each match.\n\n\n\n4.7.2 Examples\n\nSimple Search:\n\ngrep 'hello' file.txt\n\nSearches for lines containing the string “hello” in file.txt.\n\n\nCase-Insensitive Search:\n\ngrep -i 'hello' file.txt\n\nSearches for lines containing “hello”, “Hello”, “HELLO”, etc., in file.txt.\n\n\nRecursive Search:\n\ngrep -r 'function' /path/to/directory\n\nSearches for the string “function” in all files within the specified directory and its subdirectories.\n\n\nCount Matches:\n\ngrep -c 'error' logfile.txt\n\nCounts the number of lines containing the string “error” in logfile.txt.\n\n\nExclude Matches:\n\ngrep -v 'test' file.txt\n\nDisplays all lines that do not contain the string “test” in file.txt.\n\n\nDisplay Line Numbers:\n\ngrep -n 'main' program.c\n\nDisplays matching lines containing the string “main” in program.c, along with their line numbers.\n\n\n\n\n\n4.7.3 Use in Bioinformatics\ngrep is particularly useful in bioinformatics for: - Searching for specific sequences or patterns in large text files, such as FASTA or FASTQ files. - Filtering lines in output files from various bioinformatics tools. - Quickly identifying and extracting relevant information from log files, configuration files, and other textual data.\n\n\n4.7.4 Example in Bioinformatics\nSuppose you have a FASTA file (sequences.fasta) and you want to find all sequences containing the motif “ATGCGA”:\ngrep -B 1 'ATGCGA' sequences.fasta\nThis command searches for the motif “ATGCGA” and displays the matching lines along with the preceding line (which typically contains the sequence identifier in FASTA format).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Pipes and Filters</span>"
    ]
  },
  {
    "objectID": "4_Pipes_and_Filters.html#summary",
    "href": "4_Pipes_and_Filters.html#summary",
    "title": "4  Pipes and Filters",
    "section": "4.8 Summary",
    "text": "4.8 Summary\n\nwc counts lines, words, and characters in its inputs.\ncat displays the contents of its inputs.\nsort sorts its inputs.\nhead displays the first 10 lines of its input.\ntail displays the last 10 lines of its input.\ncommand &gt; [file] redirects a command’s output to a file (overwriting any existing content).\ncommand &gt;&gt; [file] appends a command’s output to a file.\n[first] | [second] is a pipeline: the output of the first command is used as the input to the second.\nThe best way to use the shell is to use pipes to combine simple single-purpose programs (filters).\ngrep is a powerful and versatile tool for text searching and processing.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Pipes and Filters</span>"
    ]
  },
  {
    "objectID": "5_loops.html",
    "href": "5_loops.html",
    "title": "5  Loops",
    "section": "",
    "text": "5.1 What is loop?\nLoops are a programming construct which allow us to repeat a command or set of commands for each item in a list. As such they are key to productivity improvements through automation. Similar to wildcards and tab completion, using loops also reduces the amount of typing required (and hence reduces the number of typing mistakes).\nSuppose we have several hundred genome data files named basilisk.dat, minotaur.dat, and unicorn.dat. For this example, we’ll use the exercise-data/creatures directory which only has three example files, but the principles can be applied to many many more files at once.\nThe structure of these files is the same: the common name, classification, and updated date are presented on the first three lines, with DNA sequences on the following lines. Let’s look at the files:\nWe would like to print out the classification for each species, which is given on the second line of each file. For each file, we would need to execute the command head -n 2 and pipe this to tail -n 1. We’ll use a loop to solve this problem, but first let’s look at the general form of a loop:",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Loops</span>"
    ]
  },
  {
    "objectID": "5_loops.html#what-is-loop",
    "href": "5_loops.html#what-is-loop",
    "title": "5  Loops",
    "section": "",
    "text": "head -n 5 basilisk.dat minotaur.dat unicorn.dat",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Loops</span>"
    ]
  },
  {
    "objectID": "5_loops.html#understanding-the-structure-of-a-for-loop-in-bash",
    "href": "5_loops.html#understanding-the-structure-of-a-for-loop-in-bash",
    "title": "5  Loops",
    "section": "5.2 Understanding the Structure of a For-Loop in Bash",
    "text": "5.2 Understanding the Structure of a For-Loop in Bash\n\nfor thing in list_of_things \n  do \n    operation_using/command $thing \n  done  \n\n\nThe word “for” indicates the start of a for-loop command:\nfor thing in list_of_things\nThis line initializes the loop, where thing is a variable that takes on the value of each item in list_of_things one at a time.\nThe word “do” indicates the start of the job execution list:\ndo\nThis marks the beginning of the commands to be executed for each item in the list.\nIndentation within the loop is not required, but aids legibility:\n    operation_using/command $thing\nWhile not mandatory, indenting the commands inside the loop improves readability, making the script easier to understand and maintain.\nThe word “done” indicates the end of a loop:\ndone\nThis signifies the end of the loop, where the script will stop iterating over the list and move on to any commands following the loop.\n\nWe can apply this to our example like this:\nfor filename in basilisk.dat minotaur.dat unicorn.dat\n do\n     echo $filename\n     head -n 2 $filename | tail -n 1\n done\n\n\n\n\n\n\nFollow the Prompt\n\n\n\nThe shell prompt changes from $ to &gt; and back again as we were typing in our loop. The second prompt, &gt;, is different to remind us that we haven’t finished typing a complete command yet. A semicolon, ;, can be used to separate two commands written on a single line.\n\n\nWhen the shell sees the keyword for, it knows to repeat a command (or group of commands) once for each item in a list. Each time the loop runs (called an iteration), an item in the list is assigned in sequence to the variable, and the commands inside the loop are executed, before moving on to the next item in the list. Inside the loop, we call for the variable’s value by putting $ in front of it. The $ tells the shell interpreter to treat the variable as a variable name and substitute its value in its place, rather than treat it as text or an external command.\nIn this example, the list is three filenames: basilisk.dat, minotaur.dat, and unicorn.dat. Each time the loop iterates, we first use echo to print the value that the variable $filename currently holds. This is not necessary for the result, but beneficial for us here to have an easier time to follow along. Next, we will run the head command on the file currently referred to by $filename. The first time through the loop, $filename is basilisk.dat. The interpreter runs the command head on basilisk.dat and pipes the first two lines to the tail command, which then prints the second line of basilisk.dat. For the second iteration, $filename becomes minotaur.dat. This time, the shell runs head on minotaur.dat and pipes the first two lines to the tail command, which then prints the second line of minotaur.dat. For the third iteration, $filename becomes unicorn.dat, so the shell runs the head command on that file, and tail on the output of that. Since the list was only three items, the shell exits the for loop.\n\n\n\n\n\n\nNote\n\n\n\nHere we see &gt; being used as a shell prompt, whereas &gt; is also used to redirect output. Similarly, $ is used as a shell prompt, but, as we saw earlier, it is also used to ask the shell to get the value of a variable.\nIf the shell prints &gt; or $ then it expects you to type something, and the symbol is a prompt.\nIf you type &gt; or $ yourself, it is an instruction from you that the shell should redirect output or get the value of a variable.\n\n\nWhen using variables it is also possible to put the names into curly braces to clearly delimit the variable name: $filename is equivalent to ${filename}, but is different from ${file}name. You may find this notation in other people’s programs.\nWe have called the variable in this loop filename in order to make its purpose clearer to human readers. The shell itself doesn’t care what the variable is called; if we wrote this loop as:\n\nfor x in basilisk.dat minotaur.dat unicorn.dat\n do\n     head -n 2 $x | tail -n 1\n done\nor:\nfor temperature in basilisk.dat minotaur.dat unicorn.dat\ndo\n   head -n 2 $temperature | tail -n 1\ndone\n\nit would work exactly the same way. Don’t do this. Programs are only useful if people can understand them, so meaningless names (like x) or misleading names (like temperature) increase the odds that the program won’t do what its readers think it does.\nIn the above examples, the variables (thing, filename, x and temperature) could have been given any other name, as long as it is meaningful to both the person writing the code and the person reading it.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Loops</span>"
    ]
  },
  {
    "objectID": "5_loops.html#challange",
    "href": "5_loops.html#challange",
    "title": "5  Loops",
    "section": "5.3 Challange",
    "text": "5.3 Challange\nCheck the contents of the folder /mnt/s-ws/everyone/Halophila_ovalis/ using ls.\n\nPrint all the file names ends with fastq.\nPrint first 6 lines of each file.\n\n\n\n\n\n\n\nTip\n\n\n\n\necho filename will print the file name\nhead -n 6 filename will print first 6 lines from the file\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nfor file in /mnt/s-ws/everyone/Halophila_ovalis/*.fastq\ndo\n    echo $file\n    tail $file\ndone",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Loops</span>"
    ]
  },
  {
    "objectID": "6_How_2_copy.html",
    "href": "6_How_2_copy.html",
    "title": "6  How do you copy to and from the remote computer?",
    "section": "",
    "text": "6.1 How Do You Copy To and From the Remote Computer?\nCopying files to and from a remote computer is a common task when working with servers or collaborating with others over a network. In Bash, you can use several tools to accomplish this, with scp (secure copy) and rsync being the most commonly used commands.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How do you copy to and from the remote computer?</span>"
    ]
  },
  {
    "objectID": "6_How_2_copy.html#how-do-you-copy-to-and-from-the-remote-computer",
    "href": "6_How_2_copy.html#how-do-you-copy-to-and-from-the-remote-computer",
    "title": "6  How do you copy to and from the remote computer?",
    "section": "",
    "text": "6.1.1 Using scp (Secure Copy)\nThe scp command allows you to securely transfer files between your local machine and a remote machine using SSH (Secure Shell). It can also be used to transfer files between two remote machines.\n\n6.1.1.1 Copying a File from Local to Remote\nscp localfile.txt username@remotehost:/path/to/remote/directory\n\nlocalfile.txt: The file you want to copy from your local machine.\nusername: Your username on the remote machine.\nremotehost: The IP address or hostname of the remote machine.\n/path/to/remote/directory: The directory on the remote machine where you want to copy the file.\n\n\n\n6.1.1.2 Example:\nscp howToCopy.txt s-99@192.1xx.xxx.xxx:/mnt/s-ws/s-99/thesis\n\n\n6.1.1.3 Copying a File from Remote to Local\nscp username@remotehost:/path/to/remotefile.txt /path/to/local/directory\n\n/path/to/remotefile.txt: The file you want to copy from the remote machine.\n/path/to/local/directory: The directory on your local machine where you want to save the file.\n\n\n\n6.1.1.4 Example:\nscp s-99@192.1xx.xxx.xxx:/mnt/s-ws/s-99/thesis/my_draft.txt .\n\n\n\n6.1.2 Using rsync\nThe rsync command is a powerful tool for copying and synchronizing files and directories between two locations over a network. It is more efficient than scp for large data transfers or regular backups because it only copies the differences between the source and the destination.\n\n6.1.2.1 Basic rsync Command\nrsync  /path/to/local/directory/ username@remotehost:/path/to/remote/directory/\n\n\n6.1.2.2 Example:\nCopying a directory from local to remote:\nrsync  howToCipy.txt mamun@146.1xx.xx.xx:/mnt/s-ws/mamun/thesis/\nCopying files and directory from remote to local:\nrsync   mamun@146.1xx.xx.xx:/mnt/s-ws/mamun/thesis/my_draft.txt .\n\nrsync   mamun@146.1xx.xx.xx:/mnt/s-ws/mamun/thesis .\n\n\n\n6.1.3 Summary\n\nscp: Simple and straightforward for copying files between local and remote machines. Best for one-time transfers.\nrsync: More efficient and powerful for synchronizing files and directories, especially useful for regular backups and large data sets.\n\nBoth scp and rsync rely on SSH for secure data transfer, ensuring that your files are copied safely over the network. Choose the tool that best fits your needs based on the complexity and frequency of your file transfer tasks.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How do you copy to and from the remote computer?</span>"
    ]
  },
  {
    "objectID": "7_bioinformatics_workflow.html",
    "href": "7_bioinformatics_workflow.html",
    "title": "7  A typical bioinformatics workflow",
    "section": "",
    "text": "Scenario: Improving Drought Resistance in Wheat",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A typical bioinformatics workflow</span>"
    ]
  },
  {
    "objectID": "7_bioinformatics_workflow.html#scenario-improving-drought-resistance-in-wheat",
    "href": "7_bioinformatics_workflow.html#scenario-improving-drought-resistance-in-wheat",
    "title": "7  A typical bioinformatics workflow",
    "section": "",
    "text": "Background\nYou are a plant geneticist working at an agricultural research institute. Your team is focused on improving drought resistance in wheat, a staple crop increasingly affected by climate change. You aim to identify genetic variations that confer drought resistance to develop new, resilient wheat varieties.\n\n\nStep 1: Sample Collection\nYou collect leaf samples from two sets of wheat plants: those that have shown high drought resistance (resistant group) and those that are sensitive to drought (sensitive group).\n\n\n\nStep 2: DNA Extraction and Sequencing\nIn the lab, your team extracts DNA from the leaf samples. You then use a high-throughput sequencing platform (such as Illumina HiSeq) to sequence the genomes of both the resistant and sensitive wheat plants. This generates millions of short DNA reads.\n\n\n\nStep 3: Quality Control\nThe raw sequencing data undergoes quality control checks to ensure high accuracy. Low-quality reads and adapter sequences are filtered out.\n\n\n\nStep 4: Alignment to the Reference Genome\nYou use Bowtie2 to align the sequencing reads to the wheat reference genome (IWGSC RefSeq v1.0). This reference genome provides a standard framework for comparison.\n\nBowtie2 maps each read to its most likely location on the wheat reference genome. This step helps in determining where each short sequence comes from within the genome.\n\n\nStep 5: Variant Calling\nAfter alignment, you use variant calling software (such as GATK) to identify genetic differences between the resistant and sensitive groups compared to the reference genome. These differences include SNPs, insertions, and deletions.\n\n\n\nStep 6: Filtering and Annotation\nGenome annotation is the process of identifying and marking the locations of genes and other functional elements within a genome sequence. It involves both structural and functional annotation.\nThe identified variants are filtered to focus on those that are unique to the drought-resistant plants and potentially beneficial. You annotate these variants using databases like Ensembl Plants to predict their functional impact.\n\n\nStep 7: Data Analysis\nYou perform statistical analyses to compare the genetic profiles of the resistant and sensitive groups. You identify several candidate genes and mutations associated with drought resistance.\n\n\nStep 8: Validation and Functional Studies\nThe candidate genes and mutations undergo further validation through additional sequencing and functional studies. You collaborate with molecular biologists to study the effects of these mutations on plant physiology under drought conditions.\n\n\nOutcome\nYou identify a set of genetic markers associated with drought resistance in wheat. This information is used to develop molecular markers for breeding programs, enabling the selection of drought-resistant varieties. The findings are published in a scientific journal, contributing to the development of more resilient wheat crops and enhancing food security.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A typical bioinformatics workflow</span>"
    ]
  },
  {
    "objectID": "7_seq_to_Alignment.html",
    "href": "7_seq_to_Alignment.html",
    "title": "8  From Sequencing to Genome Alignment",
    "section": "",
    "text": "8.1 Sequencing\nDescription: Sequencing is the process of determining the nucleotide sequence of a DNA molecule. Modern sequencing technologies, such as Illumina, PacBio, and Oxford Nanopore, generate large amounts of raw sequence data.\nFiles Produced: - FASTQ: Contains raw sequencing reads with associated quality scores.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>From Sequencing to Genome Alignment</span>"
    ]
  },
  {
    "objectID": "7_seq_to_Alignment.html#sequencing",
    "href": "7_seq_to_Alignment.html#sequencing",
    "title": "8  From Sequencing to Genome Alignment",
    "section": "",
    "text": "8.1.1 What’s a fastq file?\nA FASTQ file consists of a series of records, with each record representing a single sequence read. Each record typically consists of four lines in the following format:\n\nSequence Identifier (ID) Line: Begins with a “@” symbol and contains a unique identifier for the sequence read. This line is used to keep track of the individual read and may include additional information about the read and the sequencing process.\nSequence Line: Contains the actual DNA or RNA nucleotide sequence of the read. It consists of a string of characters, where each character represents a specific nucleotide (A for adenine, C for cytosine, G for guanine, and T for thymine in DNA, or U for uracil in RNA).\nQuality Identifier Line: Starts with a “+” symbol and is usually just a repetition of the identifier from the Sequence Line.\nQuality Scores Line: Contains a string of characters representing the quality scores of the corresponding bases in the Sequence Line.\n\nLet’s have a better look!\nhead -4 /mnt/s-ws/everyone/Halophila_ovalis/HWWJ5CCXX_8_160602_FR07958939_Other__R_160601_ANISEV_DNA_M001_R1.fastq.first_1000000.fastq\n\n\n8.1.1.1 Quality\nThe quality, also called phred score, is the probability that the corresponding basecall is incorrect.\nPhred scores use a logarithmic scale, and are represented by ASCII characters, mapping to a quality usually going from 0 to 40.\n\n\n\n\n\n\n\n\nPhred Quality Score\nProbability of incorrect base call\nBase call accuracy\n\n\n\n\n10\n1 in 10\n90%\n\n\n20\n1 in 100\n99%\n\n\n30\n1 in 1000\n99.9%\n\n\n40\n1 in 10,000\n99.99%\n\n\n50\n1 in 100,000\n99.999%\n\n\n60\n1 in 1,000,000\n99.9999%\n\n\n\n\n\n\n8.1.2 Some sanity checks first\n4 lines per reads We don’t want to work with broken data. Let’s count how many reads are in each file! A fastq file has 4 lines for each read\nwc -l /mnt/s-ws/everyone/Halophila_ovalis/*fastq\nCheck out last lines (broken copies usually have broken last line) tail gives you X last lines, -4 gives you the last read\ntail -4 /mnt/s-ws/everyone/Zostera_marina/SRR9879327.sra_1.first_1000000.fastq\nlet’s look at them all\nfor fastq_file in /mnt/s-ws/everyone/Halophila_ovalis/*fastq;\n do\n   echo $l # print the name of the file\n   tail -4 $fastq_file # print the last four lines\n done\nOther possibilities: Check md5sum md5sum is a tiny combination of letters which is generated based on the content of the file. It can be used to proof that a file is identical with another one\nmd5sum /mnt/s-ws/everyone/Zostera_marina/SRR9879327.sra_1.first_1000000.fastq\nThe long thing 92764326cc31706559eb20dab0ce4142 is the MD5 hash, this is reasonably unique for this particular file and can be used to identify it, or to check whether two files are identical (NOTE: In some rare cases two files can have the same md5sum, but for all intents and purposes we can ignore that, it’s extremely rare to happen by chance)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>From Sequencing to Genome Alignment</span>"
    ]
  },
  {
    "objectID": "7_seq_to_Alignment.html#quality-control-and-trimming",
    "href": "7_seq_to_Alignment.html#quality-control-and-trimming",
    "title": "8  From Sequencing to Genome Alignment",
    "section": "8.2 Quality Control and Trimming",
    "text": "8.2 Quality Control and Trimming\nDescription: Ensuring the quality of raw sequencing data is critical. This step involves identifying and filtering out low-quality reads and adapter sequences.\n\nFiles Produced: - Trimmed FASTQ: Quality-filtered reads.\nTools/Software: - FastQC: Quality assessment of raw reads. - Trimmomatic or Cutadapt: Trimming adapters and low-quality bases.\n\n8.2.1 FastQC\nLet’s look at sequencing qualities - we’ll use FASTQC. FastQC (Fast Quality Control) is a widely used bioinformatics tool designed to assess the quality of high-throughput sequencing data, such as data generated from next-generation sequencing (NGS) platforms. https://www.bioinformatics.babraham.ac.uk/projects/fastqc/\n\n8.2.1.1 Running FastQC for Quality Check\nTo run FastQC on a specific FASTQ file, you can use the following command:\n./fastqc -o output/filename input_fastq_file\n\n/mnt/s-ws/everyone/FastQC/fastqc -o /mnt/s-ws/s-100/myresults /mnt/s-ws/everyone/Zostera_marina/SRR9879327.sra_1.first_1000000.fastq\n\n\n8.2.1.2 Breaking Down the Command\n\nFastQC Executable Path:\n/mnt/s-ws/everyone/FastQC/fastqc\nThis is the path to the FastQC executable. Make sure to use the correct path where FastQC is installed on your system.\nOutput Directory Option (-o):\n-o /mnt/s-ws/s-100/myresults\nThe -o option specifies the directory where FastQC will save its output files. In this example, the results will be saved to /mnt/s-ws/s-100/myresults. Make sure that you have created a folder myresults in your working directory.\nInput FASTQ File:\n/mnt/s-ws/everyone/Zostera_marina/SRR9879327.sra_1.first_1000000.fastq\nThis is the path to the FASTQ file you want to analyze. In this example, it is /mnt/s-ws/everyone/Zostera_marina/SRR9879327.sra_1.first_1000000.fastq.\nCheck Results: Once the command finishes running, navigate to the output directory to check the results:\ncd /mnt/s-ws/s-100/myresults\nYou will find several files, including:\n\nA .html file: An interactive report with various quality metrics.\nA .zip file: Contains all the raw data and plots used in the HTML report.\n\n\nOpen the HTML file in a web browser to view the detailed quality report.\n\n\n8.2.1.3 FastQC report\nA FastQC report is a quality control report generated by the FastQC software, which is widely used to assess the quality of sequencing data, particularly data from high-throughput sequencing technologies like Illumina. The FastQC report provides valuable insights into the quality of the raw sequencing data and helps to identify potential issues that might affect downstream analyses.\nHere’s an explanation of the key components and sections typically found in a FastQC report:\n\nBasic Statistics: This section provides general statistics about the input data, such as the total number of reads, the read length distribution, the percentage of GC content, and the overall sequence duplication levels. These statistics give an overview of the sequencing run and provide information about the diversity and complexity of the library.\nPer Base Sequence Quality: This section displays a graph showing the average quality scores for each position in the read. Quality scores are represented using Phred scores, and a higher Phred score indicates higher sequencing accuracy. This graph helps identify regions of the read with lower quality, which might be affected by sequencing errors or other issues.\nPer Sequence Quality Scores: In this section, a box plot or histogram is provided to show the distribution of quality scores across all reads. It helps assess the overall quality of the sequencing data and identify any systematic biases or anomalies.\nPer Base Sequence Content: This section shows the percentage of each nucleotide (A, C, G, T, or U) at each position in the read. It helps identify biases in nucleotide composition that might indicate issues with library preparation or sequencing chemistry.\nPer Sequence GC Content: This graph shows the distribution of GC content across all reads in the dataset. Deviations from the expected GC content could indicate problems with the library or biases in the sequencing process.\nPer Base N Content: The graph in this section shows the percentage of ambiguous or undetermined bases (N) at each position in the read. High N content might indicate sequencing or library preparation issues.\nSequence Length Distribution: This section provides a histogram of read lengths, helping to identify any variations in read length that might affect downstream analyses.\nOverrepresented Sequences: In this section, FastQC lists any sequences that are overrepresented in the dataset. These could be contaminants or adapter sequences that need to be removed before further analysis.\nAdapter Content: This section checks for the presence of known adapter sequences in the reads. If adapters are detected, it suggests potential issues with library preparation or sequencing.\n\n\n\n\n8.2.2 Quality control using fastp\nFor EVERY sequencing project, you have to run quality control!\nUsually: Remove low quality regions from reads, and remove adapters\nAs a first step, let’s use a data-cleaning program to clean our reads We’ll use fastp since it’s easy to use For more information about fastp click on this link\n\n8.2.2.1 Paired-end sequence reads\nIn paired-end sequencing, DNA or RNA fragments are sequenced from both ends, producing two separate sequence reads for each fragment.\n\n\n8.2.2.2 Single end data\nfastp -i in.fstq -o out.fastq \n\n\n8.2.2.3 For paired end data\n\nfastp -i in.R1.fastq -I in.R2.fastq -o out.R1.fastq -O out.R2.fastq\n\n-i input file 1 (pair 1 for paired end read)\n-I input file 2 for paired end reads\n-o output file 1 (pair 1 for paired end read)\n-O output file 2 for paired end reads\n\nfastp -i /mnt/s-ws/everyone/Zostera_muelleri/MB_Z_ATCACG_L006_R1_001.fastq.first_1000000.fastq -o /mnt/s-ws/s-100/myresults/R1_001.fastq.first_1000000.trimmed.fastq -I /mnt/s-ws/everyone/Zostera_muelleri/MB_Z_ATCACG_L006_R2_001.fastq.first_1000000.fastq -O /mnt/s-ws/s-100/myresults/R2_001.fastq.first_1000000.trimmed.fastq\nThis should take a few seconds to minutes, will print some statistics Is the output as expected from the FASTQ output?\ncheck output files with ls and less:\nls -lh\nThis should take a few seconds to minutes, will print some statistics Is the output as expected from the FASTQ output?\ncheck output files with ls and less:\nls -lh\nwc -l /mnt/s-ws/everyone/Zostera_muelleri/MB_Z_ATCACG_L006_R1_001.fastq.first_1000000.fastq\nwc -l myresults/R1_001.fastq.first_1000000.trimmed.fastq\nwc -l /mnt/s-ws/everyone/Zostera_muelleri/MB_Z_ATCACG_L006_R2_001.fastq.first_1000000.fastq\nwc -l myresults/R2_001.fastq.first_1000000.trimmed.fastq",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>From Sequencing to Genome Alignment</span>"
    ]
  },
  {
    "objectID": "7_seq_to_Alignment.html#genome-alignment",
    "href": "7_seq_to_Alignment.html#genome-alignment",
    "title": "8  From Sequencing to Genome Alignment",
    "section": "8.3 Genome Alignment",
    "text": "8.3 Genome Alignment\nNow we have cleaned reads. That concludes the QC part and we can actually start on the biology! Genome alignment refers to the process of comparing and aligning entire genomes or large genomic segments to identify regions of similarity, differences, and structural variations. This process is crucial in comparative genomics, evolutionary biology, and functional genomics.\nWe’ll align these reads against two given references to see whether we can find any missing genes. We’ll use bowtie2 to align these reads.\n\nA reference genome is a collection of contigs\nA contig is a stretch of DNA sequence encoded as A,G,C,T,N\nTypically comes in FASTA format.\n\n\n8.3.1 bowtie2\nbowtie2 is a widely used bioinformatics tool that aligns DNA or RNA sequencing reads to a reference genome. bowtie2\n\n\n8.3.2 Build and index the reference database using bowtie2\nTo use Bowtie2, you must first create an index of the reference genome or transcriptome you want to align your reads to. Indexing is a preprocessing step that allows Bowtie2 to rapidly search for and align reads against the reference. You only need to index the reference once, and it generates a set of files with specific extensions that Bowtie2 uses during the alignment process. The indexing is done using the bowtie2-build command:\nbowtie2-build reference_genome.fasta reference_index\nHere, reference_genome.fasta is the file containing the reference genome sequence, and reference_index is for the generated index files.\nbowtie2-build /mnt/s-ws/everyone/scie4002_refs/najas.fasta /mnt/s-ws/s-100/myresults/najas_reference\n\nls /mnt/s-ws/s-100/myresults/*najas* -lh \n\n\n8.3.3 Align your cleaned reads with the reference\nAfter indexing the reference, you can align your sequencing reads using Bowtie2. The typical input for Bowtie2 is paired-end reads (two separate files containing forward and reverse reads) or single-end reads (one file). The basic command to align reads is:\nbowtie2 -x reference_index -1 forward_reads.fastq -2 reverse_reads.fastq -S output.sam\nIn this command:\n\n-x specifies the indexed reference genome.\n-1 and -2 provide the paths to the input FASTQ files containing paired-end reads (forward and reverse reads).\n-S designates the output file in SAM format, which contains the alignment results.\n\nbowtie2 -x /mnt/s-ws/s-100/myresults/najas_reference -1 /mnt/s-ws/s-100/myresults/R1_001.fastq.first_1000000.trimmed.fastq -2 /mnt/s-ws/s-100/myresults/R2_001.fastq.first_1000000.trimmed.fastq -S /mnt/s-ws/s-100/myresults/Alignments.sam \n\n\n8.3.4 Output and Formats:\nBowtie2 generates alignment results in SAM (Sequence Alignment/Map) format by default. The output SAM file contains information about each read’s alignment position, quality, and other mapping-related details. You can further process the SAM file using other bioinformatics tools for downstream analysis. A typical SAM (Sequence Alignment/Map) file is a text-based format used to store the results of sequence read alignments to a reference genome or transcriptome. It provides a standardized way to represent the mapping information, quality scores, and additional metadata for each aligned read. SAM files are widely used in bioinformatics and are essential for various downstream analyses, including variant calling, gene expression quantification, and genome assembly.\nHere’s a description of the main components of a typical SAM file:\n\nHeader Section: The SAM file starts with the header section, which contains metadata and information about the reference genome, software used, and other optional details. The header lines begin with the ‘@’ symbol.\nAlignment Records: Following the header section, each alignment record corresponds to a single read that has been aligned to the reference genome. Alignment records start with fixed fields, each separated by a tab character, representing important information about the read and its alignment.\n\nQNAME: Read name or identifier. It should be unique within the file.\nFLAG: Bitwise flags representing various properties of the read and alignment, such as paired-end, strand, read unmapped, etc.\nRNAME: Reference sequence name where the read is aligned. It refers to the reference genome sequence identifier. If there will be no alignmet, it will be a “*“. \"*\" is the special letter SAM files use to mean ‘no reference sequence’\nPOS: 1-based leftmost position of the aligned read on the reference genome.\nMAPQ: Mapping quality score, representing the confidence of the alignment.\nCIGAR: CIGAR string indicating the alignment details, including matches, insertions, deletions, etc.\nRNEXT: Reference sequence name of the mate/next read for paired-end data.\nPNEXT: 1-based position of the mate/next read on the reference genome for paired-end data.\nTLEN: Signed observed template length for paired-end data.\nSEQ: Read sequence.\nQUAL: Quality scores corresponding to each base in the read sequence.\n\nOptional Fields: After the fixed fields, there can be optional fields that provide additional information about the read, alignment, or experimental conditions. These fields are tab-separated and have a TAG:VALUE format. For example, AS:i:100 indicates an alignment score of 100.\n\nA sample alignment record in a SAM file might look like this:\nERR1234567.1 83 chr1 100 30 50M = 200 100 ATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCG + !\"#\"$%&'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefgh\nSAM files are human-readable and can be processed using various bioinformatics tools and libraries. For more information click on this link https://samtools.github.io/hts-specs/SAMv1.pdf\n\n\n8.3.5 samtools\nFor large datasets, it is common to convert SAM files to the more space-efficient BAM format using tools like samtools, as it enables faster processing and better utilization of computational resources.\nbowtie2 -x /mnt/s-ws/s-100/myresults/najas_reference -1 /mnt/s-ws/s-100/myresults/R1_001.fastq.first_1000000.trimmed.fastq -2 /mnt/s-ws/s-100/myresults/R2_001.fastq.first_1000000.trimmed.fastq | samtools sort -o /mnt/s-ws/s-100/myresults/Alignments_sorted.bam\n\n8.3.5.1 Sanity check - how many reads align?\nsamtools view Alignments_sorted.bam  | grep -v '*' | wc -l\nThis means: grep -v searches for the opposites, so remove all lines with ,  is the special letter SAM files use to mean ‘no reference sequence’ and then count the lines\n\n\n8.3.5.2 Aligned reads output to a text file\nsamtools view /mnt/s-ws/s-100/myresults/Alignments_sorted.bam  | grep -v '*' &gt; /mnt/s-ws/s-100/myresults/aligned_reads.txt\n\n\n\n8.3.6 Use bedtools to check which genes are covered by reads\nBedtools provides a collection of powerful command-line tools that allow to perform various operations on genomic intervals, including intersections, unions, subsetting, merging, and more. A fantastic tutorial on bedtools can be found here: http://quinlanlab.org/tutorials/bedtools/bedtools.html\n\n\n8.3.7 GFF3 File format\nA GFF3 (Generic Feature Format Version 3) file is a standard text-based file format commonly used in bioinformatics to represent genomic annotations and features. GFF3 files provide a structured and standardized way to describe the location, properties, and attributes of various biological features on a reference genome, such as genes, exons, transcripts, and other genomic elements.\nHere’s a brief overview of the key components of a GFF3 file:\n\nHeader Lines: The GFF3 file may start with optional header lines that provide general information about the data and the source of the annotations. Header lines typically begin with the ‘##’ symbol.\nFeature Lines: The main part of the GFF3 file consists of feature lines, each representing a genomic feature or annotation. Feature lines have nine tab-separated columns, which define specific attributes of the feature:\n\nColumn 1 (seqid): Name of the reference sequence (e.g., chromosome or contig) where the feature is located.\nColumn 2 (source): The source or program that generated the annotation, often a database or bioinformatics tool.\nColumn 3 (type): The type of the genomic feature (e.g., gene, mRNA, exon, CDS, etc.). This follows controlled vocabulary terms such as “gene,” “exon,” and “mRNA.”\nColumn 4 (start): Start position of the feature on the reference sequence. It is 1-based, meaning the first position is represented as 1.\nColumn 5 (end): End position of the feature on the reference sequence (inclusive).\nColumn 6 (score): An optional numeric value representing the confidence or score of the feature. Often used for quantitative data like expression levels.\nColumn 7 (strand): The strand of the feature, indicated by a “+” (forward strand) or “-” (reverse strand).\nColumn 8 (phase): For features like coding sequences (CDS), this column specifies the reading frame (0, 1, or 2) with respect to the start codon.\nColumn 9 (attributes): A semicolon-separated list of key-value pairs representing additional information about the feature. Common attributes include gene IDs, transcript IDs, gene names, and other feature-specific details.\n\nComment Lines: GFF3 files may also include comment lines that provide additional context or explanations for the annotations.\n\nGFF3 files are widely used in genome annotation projects, as they offer a consistent and flexible format to store genomic feature data. Various bioinformatics tools and genome browsers support GFF3 files, allowing researchers to visualize and analyze genomic annotations effectively.\nUse bedtools to check which genes are covered by reads\nbedtools intersect -a /mnt/s-ws/everyone/scie4002_refs/najas.gff3 -b /mnt/s-ws/s-100/myresults/Alignments_sorted.bam | grep gene | less\nThe command bedtools intersect is used to find overlapping features between two files, one in BED/GFF/GTF format (-a), and the other in BAM format (-b).\nIn this specific case: - -a /mnt/s-ws/everyone/scie4002_refs/najas.gff3: This specifies the input file in GFF3 format, containing features (e.g., genes, transcripts, regions) of interest from the “najas” reference genome. - -b /mnt/s-ws/s-100/myresults/Alignments_sorted.bam: This specifies the input file in BAM format, containing read alignments (typically from a sequencing experiment) aligned to the “najas” reference genome.\nThe command will identify any overlapping features between the GFF3 file and the aligned reads in the BAM file. The resulting output will show which reads align to the annotated features in the GFF3 file, providing information about the spatial relationship between the reads and the annotated genomic elements.\nThe | (pipe) symbol is used to pass the output of the bedtools intersect command as input to the grep command. The grep command is then used to filter the output and only show lines containing the word “gene.”\nIn summary, the entire command will identify any overlapping features between the GFF3 file and the aligned reads in the BAM file and then filter the output to show only those lines that correspond to genes present in the GFF3 file. This can help extract information specifically related to genes from the alignment results.\n\n8.3.7.1 Can you output this to a text file?\nNow we’ll use bedtools to check whether any reads don’t align to our given genes\nbedtools intersect -v -a /mnt/s-ws/everyone/scie4002_refs/najas.gff3 -b /mnt/s-ws/s-100/myresults/Alignments_sorted.bam | grep gene | less\n\n-v means invert - which genes have 0 coverage?\nWhat are these genes?\n\nGoogle!",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>From Sequencing to Genome Alignment</span>"
    ]
  },
  {
    "objectID": "7_File_Format.html",
    "href": "7_File_Format.html",
    "title": "9  File Format",
    "section": "",
    "text": "10 File Formats\nThis lecture is aimed at making you discover the most popular file formats used in bioinformatics. ## Table of Contents * The fasta format * The fastq format * The sam/bam format * The vcf format * The gff format\n\n10.0.1 The fasta format\nThe fasta format was invented in 1988 and designed to represent nucleotide or peptide sequences. It originates from the FASTA software package, but is now a standard in the world of bioinformatics.\nThe first line in a FASTA file starts with a “&gt;” (greater-than) symbol followed by the description or identifier of the sequence. Following the initial line (used for a unique description of the sequence) is the actual sequence itself in standard one-letter code.\nA few sample sequences:\n&gt;KX580312.1 Homo sapiens truncated breast cancer 1 (BRCA1) gene, exon 15 and partial cds\nGTCATCCCCTTCTAAATGCCCATCATTAGATGATAGGTGGTACATGCACAGTTGCTCTGGGAGTCTTCAG\nAATAGAAACTACCCATCTCAAGAGGAGCTCATTAAGGTTGTTGATGTGGAGGAGTAACAGCTGGAAGAGT\nCTGGGCCACACGATTTGACGGAAACATCTTACTTGCCAAGGCAAGATCTAG\n&gt;KRN06561.1 heat shock [Lactobacillus sucicola DSM 21376 = JCM 15457]\nMSLVMANELTNRFNNWMKQDDFFGNLGRSFFDLDNSVNRALKTDVKETDKAYEVRIDVPGIDKKDITVDY\nHDGVLSVNAKRDSFNDESDSEGNVIASERSYGRFARQYSLPNVDESGIKAKCEDGVLKLTLPKLAEEKIN\nGNHIEIE\nA fasta file can contain multiple sequence. Each sequence will be separated by their “header” line, starting by “&gt;”.\nExample:\n&gt;KRN06561.1 heat shock [Lactobacillus sucicola DSM 21376 = JCM 15457]\nMSLVMANELTNRFNNWMKQDDFFGNLGRSFFDLDNSVNRALKTDVKETDKAYEVRIDVPGIDKKDITVDY\nHDGVLSVNAKRDSFNDESDSEGNVIASERSYGRFARQYSLPNVDESGIKAKCEDGVLKLTLPKLAEEKIN\nGNHIEIE\n&gt;3HHU_A Chain A, Human Heat-Shock Protein 90 (Hsp90)\nMPEETQTQDQPMEEEEVETFAFQAEIAQLMSLIINTFYSNKEIFLRELISNSSDALDKIRYESLTDPSKL\nDSGKELHINLIPNKQDRTLTIVDTGIGMTKADLINNLGTIAKSGTKAFMEALQAGADISMIGQFGVGFYS\nAYLVAEKVTVITKHNDDEQYAWESSAGGSFTVRTDTGEPMGRGTKVILHLKEDQTEYLEERRIKEIVKKH\nSQFIGYPITLFVEK\n\n\n10.0.2 The fastq format\nThe fastq format is also a text based format to represent nucleotide sequences, but also contains the corresponding quality of each nucleotide. It is the standard for storing the output of high-throughput sequencing instruments such as the Illumina machines.\nA fastq file uses four lines per sequence:\n\nLine 1 begins with a ‘@’ character and is followed by a sequence identifier and an optional description (like a FASTA title line).\nLine 2 is the raw sequence letters.\nLine 3 begins with a ‘+’ character and is optionally followed by the same sequence identifier (and any description) again.\nLine 4 encodes the quality values for the sequence in Line 2, and must contain the same number of symbols as letters in the sequence.\n\nAn example sequence in fastq format:\n@SEQ_ID\nGATTTGGGGTTCAAAGCAGTATCGATCAAATAGTAAATCCATTTGTTCAACTCACAGTTT\n+\n!''*((((***+))%%%++)(%%%%).1***-+*''))**55CCF&gt;&gt;&gt;&gt;&gt;&gt;CCCCCCC65\n\n10.0.2.1 Quality\nThe quality, also called phred score, is the probability that the corresponding basecall is incorrect.\nPhred scores use a logarithmic scale, and are represented by ASCII characters, mapping to a quality usually going from 0 to 40.\n\n\n\n\n\n\n\n\nPhred Quality Score\nProbability of incorrect base call\nBase call accuracy\n\n\n\n\n10\n1 in 10\n90%\n\n\n20\n1 in 100\n99%\n\n\n30\n1 in 1000\n99.9%\n\n\n40\n1 in 10,000\n99.99%\n\n\n50\n1 in 100,000\n99.999%\n\n\n60\n1 in 1,000,000\n99.9999%\n\n\n\n\n\n\n10.0.3 the sam/bam format\nFrom Wikipedia:\nSAM (file format) is a text-based format for storing biological sequences aligned to a reference sequence developed by Heng Li. The acronym SAM stands for Sequence Alignment/Map. It is widely used for storing data, such as nucleotide sequences, generated by Next generation sequencing technologies and usually mapped to a reference.\nThe SAM format consists of a header and an alignment section. The binary representation of a SAM file is a BAM file, which is a compressed SAM file.[1] SAM files can be analysed and edited with the software SAMtools.\nThe SAM format has a really extensive and complex specification that you can find here.\nIn brief it consists of a header section and reads (with other information) in tab delimited format.\n\n10.0.3.1 Example header section\n@HD VN:1.0                  SO:unsorted\n@SQ SN:O_volvulusOVOC_OM1a  LN:2816604\n@SQ SN:O_volvulusOVOC_OM1b  LN:28345163\n@SQ SN:O_volvulusOVOC_OM2   LN:25485961\n\n\n10.0.3.2 Example read\nM01137:130:00-A:17009:1352/14 * 0 0 * * 0 0 AGCAAAATACAACGATCTGGATGGTAGCATTAGCGATGCGACACTGCTTGAACCGTCAAAG FGGFGCFGFFGC8,,@D?E6EFCF,=AEFFGGDGGGADFGG@&gt;FFEGGG:+&lt;7D&gt;AFCFGG YT:Z:UU\n\n\n\n10.0.4 the vcf format\nThe vcf format is also a text-based file format. VCF stands for Variant Call Format and is used to store gene sequence variations (SNVs, indels). The format has been developped for genotyping projects, and is the standard to represent variations in the genome of a species.\nA vcf is a tab-delimited file, described here.\n\n10.0.4.1 VCF Example\n##fileformat=VCFv4.0\n##fileDate=20110705\n##reference=1000GenomesPilot-NCBI37\n##phasing=partial\n##INFO=&lt;ID=NS,Number=1,Type=Integer,Description=\"Number of Samples With Data\"&gt;\n##INFO=&lt;ID=DP,Number=1,Type=Integer,Description=\"Total Depth\"&gt;\n##INFO=&lt;ID=AF,Number=.,Type=Float,Description=\"Allele Frequency\"&gt;\n##INFO=&lt;ID=AA,Number=1,Type=String,Description=\"Ancestral Allele\"&gt;\n##INFO=&lt;ID=DB,Number=0,Type=Flag,Description=\"dbSNP membership, build 129\"&gt;\n##INFO=&lt;ID=H2,Number=0,Type=Flag,Description=\"HapMap2 membership\"&gt;\n##FILTER=&lt;ID=q10,Description=\"Quality below 10\"&gt;\n##FILTER=&lt;ID=s50,Description=\"Less than 50% of samples have data\"&gt;\n##FORMAT=&lt;ID=GQ,Number=1,Type=Integer,Description=\"Genotype Quality\"&gt;\n##FORMAT=&lt;ID=GT,Number=1,Type=String,Description=\"Genotype\"&gt;\n##FORMAT=&lt;ID=DP,Number=1,Type=Integer,Description=\"Read Depth\"&gt;\n##FORMAT=&lt;ID=HQ,Number=2,Type=Integer,Description=\"Haplotype Quality\"&gt;\n#CHROM POS    ID        REF  ALT     QUAL FILTER INFO                              FORMAT      Sample1        Sample2        Sample3\n2      4370   rs6057    G    A       29   .      NS=2;DP=13;AF=0.5;DB;H2           GT:GQ:DP:HQ 0|0:48:1:52,51 1|0:48:8:51,51 1/1:43:5:.,.\n2      7330   .         T    A       3    q10    NS=5;DP=12;AF=0.017               GT:GQ:DP:HQ 0|0:46:3:58,50 0|1:3:5:65,3   0/0:41:3\n2      110696 rs6055    A    G,T     67   PASS   NS=2;DP=10;AF=0.333,0.667;AA=T;DB GT:GQ:DP:HQ 1|2:21:6:23,27 2|1:2:0:18,2   2/2:35:4\n2      130237 .         T    .       47   .      NS=2;DP=16;AA=T                   GT:GQ:DP:HQ 0|0:54:7:56,60 0|0:48:4:56,51 0/0:61:2\n2      134567 microsat1 GTCT G,GTACT 50   PASS   NS=2;DP=9;AA=G                    GT:GQ:DP    0/1:35:4       0/2:17:2       1/1:40:3\nchr1    45796269        .       G       C\nchr1    45797505        .       C       G\nchr1    45798555        .       T       C\nchr1    45798901        .       C       T\nchr1    45805566        .       G       C\nchr2    47703379        .       C       T\nchr2    48010488        .       G       A\nchr2    48030838        .       A       T\nchr2    48032875        .       CTAT    -\nchr2    48032937        .       T       C\nchr2    48033273        .       TTTTTGTTTTAATTCCT       -\nchr2    48033551        .       C       G\nchr2    48033910        .       A       T\nchr2    215632048       .       G       T\nchr2    215632125       .       TT      -\nchr2    215632155       .       T       C\nchr2    215632192       .       G       A\nchr2    215632255       .       CA      TG\nchr2    215634055       .       C       T\n\n\n\n10.0.5 the gff format\nThe general feature format (gff) is another text file format, used for describing genes and other features of DNA, RNA and protein sequences. It is the standard for annotation of genomes.\nA gff file should contain 9 columns, described here\n\n10.0.5.1 Example gff\n##description: evidence-based annotation of the human genome (GRCh38), version 25 (Ensembl 85)\n##provider: GENCODE\n##contact: gencode-help@sanger.ac.uk\n##format: gtf\n##date: 2016-07-15\nchr1    HAVANA  gene    11869   14409   .   +   .   gene_id \"ENSG00000223972.5\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_status \"KNOWN\"; gene_name \"DDX11L1\"; level 2; havana_gene \"OTTHUMG00000000961.2\";\nchr1    HAVANA  transcript  11869   14409   .   +   .   gene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000456328.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_status \"KNOWN\"; gene_name \"DDX11L1\"; transcript_type \"processed_transcript\"; transcript_status \"KNOWN\"; transcript_name \"DDX11L1-002\"; level 2; transcript_support_level \"1\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000362751.1\";\nchr1    HAVANA  exon    11869   12227   .   +   .   gene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000456328.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_status \"KNOWN\"; gene_name \"DDX11L1\"; transcript_type \"processed_transcript\"; transcript_status \"KNOWN\"; transcript_name \"DDX11L1-002\"; exon_number 1; exon_id \"ENSE00002234944.1\"; level 2; transcript_support_level \"1\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000362751.1\";\nchr1    HAVANA  exon    12613   12721   .   +   .   gene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000456328.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_status \"KNOWN\"; gene_name \"DDX11L1\"; transcript_type \"processed_transcript\"; transcript_status \"KNOWN\"; transcript_name \"DDX11L1-002\"; exon_number 2; exon_id \"ENSE00003582793.1\"; level 2; transcript_support_level \"1\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000362751.1\";\nchr1    HAVANA  exon    13221   14409   .   +   .   gene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000456328.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_status \"KNOWN\"; gene_name \"DDX11L1\"; transcript_type \"processed_transcript\"; transcript_status \"KNOWN\"; transcript_name \"DDX11L1-002\"; exon_number 3; exon_id \"ENSE00002312635.1\"; level 2; transcript_support_level \"1\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000362751.1\";",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>File Format</span>"
    ]
  }
]